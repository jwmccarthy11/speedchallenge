{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "CROP_DIM = (0, 40, 640, 360)\n",
    "NEW_SIZE = (200, 100)\n",
    "\n",
    "def op_flow_raw(img0, img1):\n",
    "    gray0 = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        gray0, gray1, None, 0.5, 3, 5, 3, 5, 1.1, 0\n",
    "    )\n",
    "    return flow\n",
    "\n",
    "def op_flow_bgr(flow, shape):\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    mask[..., 0] = ang * 180 / np.pi / 2    # direction\n",
    "    mask[..., 1] = 255                      # full saturation\n",
    "    mask[..., 2] = cv2.normalize(           # intensity\n",
    "        mag, None, 0, 255, cv2.NORM_MINMAX\n",
    "    )\n",
    "    bgr = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    return bgr\n",
    "\n",
    "def format_frame(frame):\n",
    "    img = Image.fromarray(frame).crop(CROP_DIM).resize(NEW_SIZE)\n",
    "    return np.array(img)\n",
    "\n",
    "def split_video(video):\n",
    "    frames, op_flows, op_bgrs = [], [], []\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    pbar = tqdm(total=cap.get(cv2.CAP_PROP_FRAME_COUNT), position=0, leave=2)\n",
    "    ret, frame1 = cap.read()\n",
    "    frame1 = format_frame(frame1)\n",
    "    while ret:\n",
    "        ret, frame2 = cap.read()\n",
    "        if ret:\n",
    "            frame2 = format_frame(frame2)\n",
    "            frames.append(frame2)\n",
    "            op_flow = op_flow_raw(frame1, frame2)\n",
    "            op_flows.append(op_flow)\n",
    "            op_bgr = op_flow_bgr(op_flow, frame2.shape)\n",
    "            op_bgrs.append(op_bgr)\n",
    "            frame1 = frame2\n",
    "            pbar.update()\n",
    "        else:\n",
    "            print('Finished saving '+video)\n",
    "    return np.array(frames), np.array(op_flows), np.array(op_bgrs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Data Pipeline\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 20399/20400.0 [02:57<00:00, 108.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished saving ./data/train.mp4\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./data/train.h5', 'w') as f:\n",
    "    frm, opf, opv = split_video('./data/train.mp4')\n",
    "    f.create_dataset('FRM', frm.shape, data=frm)\n",
    "    f.create_dataset('OPF', opf.shape, data=opf)\n",
    "    f.create_dataset('OPV', opv.shape, data=opv)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Save frames and optical flow\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with h5py.File('./data/train.h5', 'r') as f:\n",
    "    frm = f['FRM']\n",
    "    opv = f['OPV']\n",
    "    for a, b in zip(frm, opv):\n",
    "        cv2.imshow('FRM', a)\n",
    "        cv2.imshow('OPV', b)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% View\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class SpeedDataset(Dataset):\n",
    "    def __init__(self, filename, transform=None):\n",
    "        super(SpeedDataset, self).__init__()\n",
    "\n",
    "        self.file = h5py.File(filename, 'r')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file.keys())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # retrieve from h5py\n",
    "        img = np.array(self.file['IMG'+str(idx)])\n",
    "        flw = np.array(self.file['FLW'+str(idx)])\n",
    "\n",
    "        # apply transform\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img).permute(1, 2, 0)\n",
    "            flw = self.transform(flw).permute(1, 2, 0)\n",
    "\n",
    "        return img, flw\n",
    "\n",
    "dataset = SpeedDataset(\n",
    "    './data/train.h5',\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1200,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "count = 0\n",
    "for images, flows in dataloader:\n",
    "    for img in flows:\n",
    "        cv2.imshow('train', img.numpy())\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    if (count := count + 1) > 0:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Define torch dataset\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Define model\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}